## Project 1 â€“ Titanic Dataset: Data Cleaning & EDA

# Titanic Dataset: Data Cleaning & Exploratory Data Analysis (EDA)

## ğŸ“– Overview
This project performs **data cleaning and exploratory data analysis (EDA)** on the famous [Titanic dataset](https://www.kaggle.com/c/titanic).  
The aim is to explore survival patterns, identify influential factors, and create meaningful visualizations.


## ğŸ—‚ Dataset
- **Train set**: 891 passengers, 12 features
- **Test set**: 418 passengers, 11 features
- **Gender submission file**: Survival predictions template

Key features include:
- PassengerId, Name, Sex, Age, Pclass, Fare, Cabin, Embarked
- Survival label (0 = did not survive, 1 = survived)

---

## ğŸ“ Project Structure
titanic-eda/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚ â””â”€â”€ gender_submission.csv
â”‚â”€â”€ notebooks/
â”‚ â””â”€â”€ titanic_eda.ipynb
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt


---

## ğŸ”§ Data Cleaning
- **Age**: Missing values filled using median grouped by Sex & Pclass  
- **Embarked**: Filled with mode (most common value)  
- **Cabin**: Too many missing â†’ created binary feature `HasCabin`  
- **New Features**:  
  - `FamilySize = SibSp + Parch + 1`  
  - `IsAlone` (binary)  
  - `Title` extracted from names  

---

## ğŸ“Š Exploratory Data Analysis
- **Univariate Analysis**: Survival distribution, Age distribution, Class distribution  
- **Bivariate Analysis**:  
  - Survival by Sex, Pclass, Embarked, FamilySize, Title  
- **Multivariate**: Correlation heatmap & categorical plots  

---

## ğŸ”‘ Key Findings
- Overall survival rate â‰ˆ **38%**  
- **Sex**: Females â‰ˆ 74% survival, Males â‰ˆ 19%  
- **Class**: 1st â‰ˆ 63%, 2nd â‰ˆ 47%, 3rd â‰ˆ 24%  
- **Age**: Children (<12) had higher survival, elderly (>60) much lower  
- **Family size**: Small families (2â€“4) did better, very large or solo travelers fared worse  
- **Cabin info**: Recorded cabin strongly linked to survival  
- **Titles**: Mrs, Miss, Master â†’ higher survival; Rare titles â†’ lower survival  

---

## âœ… Conclusion
- The strongest predictors of survival: **Sex, Pclass, and Age**  
- Results align with *â€œWomen and children firstâ€* policy during Titanic evacuation  
- Wealth and social status improved survival chances  

---

## â–¶ï¸ How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/titanic-eda.git
   cd titanic-eda
2. Install dependencies:
   pip install -r requirements.txt
3. Run the Jupyter notebook:
   jupyter notebook notebooks/titanic_eda.ipynb

## To-Do / Future Work

1.Build predictive survival models (Logistic Regression, Random Forest, XGBoost)
2.Perform feature importance ranking
3.Try deep learning survival prediction (Keras/TensorFlow)
4.Deploy a simple Titanic survival prediction web app

## Tools Used

1.Python (pandas, numpy, seaborn, matplotlib)
2.Jupyter/Colab for visualization

## License
This project is licensed under the MIT License â€“ you are free to use, modify, and distribute it.


## Project 2 â€“ Twitter Sentiment Analysis & EDA
# Twitter Sentiment Analysis & Exploratory Data Analysis (EDA)

## ğŸ“– Overview
This project analyzes a **Twitter dataset** containing tweets labeled with entities (brands/products) and sentiment labels.  
It includes **data cleaning, sentiment analysis (TextBlob & VADER), visualization, and topic analysis**.

---

## ğŸ—‚ Dataset
- **Training set**: ~74,681 tweets (reduced to ~69k after cleaning)
- **Validation set**: 999 tweets
- Features: `tweet_id`, `entity`, `label`, `text`


  ## ğŸ“ Project Structure
  twitter-sentiment-eda/
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ twitter_training.csv
â”‚ â””â”€â”€ twitter_validation.csv
â”‚â”€â”€ notebooks/
â”‚ â””â”€â”€ twitter_sentiment_analysis.ipynb
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt


---

## ğŸ”§ Data Cleaning
- Standardized headers (`text`, `label`, `entity`, `tweet_id`)  
- Removed duplicates and missing values  
- Cleaned text columns and normalized  

---

## ğŸ“Š Exploratory Data Analysis
1. **Sentiment Distribution** â€“ Most tweets Neutral or Positive, fewer Negative  
2. **Polarity & Subjectivity (TextBlob)** â€“  
   - Polarity clustered between 0 and +0.3 (mild positivity)  
   - Subjectivity >0.5 â†’ tweets are opinion-heavy  
3. **Entities/Brands** â€“ Microsoft, Google, Twitter, Apple most mentioned  
4. **Word Cloud & Frequent Words** â€“ mix of praise (â€œloveâ€, â€œgreatâ€) and complaints (â€œbadâ€, â€œproblemâ€)  
5. **Time Series Analysis** â€“ Polarity trends across tweet IDs  
6. **Advanced Sentiment (VADER)** â€“ Detected sarcasm and nuanced negatives better than TextBlob  
7. **Correlation** â€“ Polarity (TextBlob) vs Compound (VADER) correlation â‰ˆ 0.6  

---

## ğŸ”‘ Key Findings
- Overall sentiment on Twitter: **slightly positive, mostly neutral**  
- Brands differ in public perception â€“ some lean positive (Google), others mixed (Twitter)  
- Strong correlation between TextBlob & VADER â†’ combining improves reliability  
- Frequent negative terms highlight common complaints â†’ useful for businesses  

---

## âœ… Conclusion
This project demonstrated how **NLP sentiment analysis** can be applied to real-world Twitter data.  
Insights can help brands monitor reputation, identify problem areas, and improve engagement.  
Future work: extend to **deep learning models (BERT, RoBERTa)** and **real-time monitoring**.

---

## â–¶ï¸ How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/twitter-sentiment-eda.git
   cd twitter-sentiment-eda
2. Install dependencies:
   pip install -r requirements.txt
3. Run the Jupyter notebook:
   jupyter notebook notebooks/twitter_sentiment_analysis.ipynb

## To-Do / Future Work
1. Train and evaluate deep learning sentiment models (BERT, RoBERTa, LSTM)
2. Deploy a real-time Twitter sentiment dashboard
3. Add multilingual sentiment analysis
4. Perform topic modeling (LDA, BERTopic) for deeper insights

##  Tools Used
1. Python (pandas, numpy, seaborn, matplotlib, plotly)
2. NLP Libraries: NLTK, TextBlob, VADER
3. WordCloud for text visualization

## License
This project is licensed under the MIT License â€“ you are free to use, modify, and distribute it.

